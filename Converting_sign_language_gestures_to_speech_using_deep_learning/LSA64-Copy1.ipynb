{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "316e0ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import random\n",
    "from fractions import Fraction\n",
    "import math\n",
    "import mediapipe as mp\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4b16a0",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Resoultion is 1920 by 1080 (W/H)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96415a70",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e49534c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(path):\n",
    "    f = []\n",
    "    with os.scandir(path) as entries:\n",
    "        for entry in entries:\n",
    "            if entry.is_file():\n",
    "                f.append(entry.name)\n",
    "    return f\n",
    "\n",
    "def get_class(path):\n",
    "    return int(path.split('_')[0])\n",
    "\n",
    "def get_files_per_class(files):\n",
    "    files_for_class = {}\n",
    "    \n",
    "    for fname in files:\n",
    "        class_name = get_class(fname)\n",
    "        if files_for_class.get(class_name, 0) != 0:\n",
    "            files_for_class[class_name].append(fname)\n",
    "        else:\n",
    "            files_for_class[class_name] = [fname]\n",
    "    \n",
    "    return files_for_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3b75d114",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = get_files('./dataset/lsa64-data/all/')\n",
    "files_for_class = get_files_per_class(all_files)\n",
    "classes = list(files_for_class.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f9544d48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for key in files_for_class:\n",
    "    files_for_class[key] = list(filter(lambda x: re.match(r\"[0-9]{3}_[0-9]{3}_00[1-2].mp4\", x), files_for_class[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51eec481",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Do not Run\n",
    "# Find the average and median number of frames used for describing each word (for now n = 10) and check the frame dimensions\n",
    "\n",
    "class_frame_info = {}\n",
    "\n",
    "for class_ in files_for_class:\n",
    "    result = []\n",
    "    for file in files_for_class[class_]:\n",
    "        cap = cv2.VideoCapture(f'./dataset/lsa64-data/all/{file}')\n",
    "        result.append(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        cap.release()\n",
    "    result = np.array(result)\n",
    "    class_frame_info[class_] = {}\n",
    "    class_frame_info[class_]['mean'] = np.mean(result)\n",
    "    class_frame_info[class_]['median'] = np.median(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63963022",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'mean': 119.5, 'median': 118.0},\n",
       " 2: {'mean': 124.0, 'median': 118.0},\n",
       " 3: {'mean': 119.5, 'median': 118.0},\n",
       " 4: {'mean': 104.5, 'median': 88.0},\n",
       " 5: {'mean': 133.0, 'median': 118.0},\n",
       " 6: {'mean': 161.5, 'median': 148.0},\n",
       " 7: {'mean': 107.5, 'median': 118.0},\n",
       " 8: {'mean': 97.0, 'median': 88.0},\n",
       " 9: {'mean': 125.5, 'median': 118.0},\n",
       " 10: {'mean': 98.5, 'median': 88.0},\n",
       " 11: {'mean': 103.0, 'median': 103.0},\n",
       " 12: {'mean': 124.0, 'median': 118.0},\n",
       " 13: {'mean': 113.5, 'median': 118.0},\n",
       " 14: {'mean': 97.0, 'median': 88.0},\n",
       " 15: {'mean': 91.0, 'median': 88.0},\n",
       " 16: {'mean': 115.0, 'median': 118.0},\n",
       " 17: {'mean': 100.0, 'median': 88.0},\n",
       " 18: {'mean': 116.5, 'median': 118.0},\n",
       " 19: {'mean': 94.0, 'median': 88.0},\n",
       " 20: {'mean': 100.0, 'median': 88.0},\n",
       " 21: {'mean': 125.5, 'median': 118.0},\n",
       " 22: {'mean': 116.5, 'median': 118.0},\n",
       " 23: {'mean': 124.0, 'median': 118.0},\n",
       " 24: {'mean': 126.5, 'median': 122.0},\n",
       " 25: {'mean': 140.0, 'median': 152.0},\n",
       " 26: {'mean': 122.0, 'median': 122.0},\n",
       " 27: {'mean': 122.0, 'median': 122.0},\n",
       " 28: {'mean': 143.0, 'median': 152.0},\n",
       " 29: {'mean': 128.0, 'median': 122.0},\n",
       " 30: {'mean': 140.0, 'median': 152.0},\n",
       " 31: {'mean': 162.5, 'median': 152.0},\n",
       " 32: {'mean': 150.5, 'median': 152.0},\n",
       " 33: {'mean': 135.5, 'median': 122.0},\n",
       " 34: {'mean': 197.0, 'median': 182.0},\n",
       " 35: {'mean': 134.0, 'median': 122.0},\n",
       " 36: {'mean': 135.5, 'median': 122.0},\n",
       " 37: {'mean': 129.5, 'median': 122.0},\n",
       " 38: {'mean': 131.0, 'median': 122.0},\n",
       " 39: {'mean': 125.0, 'median': 122.0},\n",
       " 40: {'mean': 141.5, 'median': 137.0},\n",
       " 41: {'mean': 179.0, 'median': 182.0},\n",
       " 42: {'mean': 132.5, 'median': 122.0},\n",
       " 43: {'mean': 123.5, 'median': 122.0},\n",
       " 44: {'mean': 134.0, 'median': 122.0},\n",
       " 45: {'mean': 155.0, 'median': 152.0},\n",
       " 46: {'mean': 138.5, 'median': 137.0},\n",
       " 47: {'mean': 137.0, 'median': 137.0},\n",
       " 48: {'mean': 150.5, 'median': 152.0},\n",
       " 49: {'mean': 138.5, 'median': 152.0},\n",
       " 50: {'mean': 128.0, 'median': 122.0},\n",
       " 51: {'mean': 140.0, 'median': 152.0},\n",
       " 52: {'mean': 119.0, 'median': 122.0},\n",
       " 53: {'mean': 126.5, 'median': 122.0},\n",
       " 54: {'mean': 135.5, 'median': 122.0},\n",
       " 55: {'mean': 108.5, 'median': 107.0},\n",
       " 56: {'mean': 125.0, 'median': 122.0},\n",
       " 57: {'mean': 129.5, 'median': 122.0},\n",
       " 58: {'mean': 132.5, 'median': 122.0},\n",
       " 59: {'mean': 117.5, 'median': 122.0},\n",
       " 60: {'mean': 129.5, 'median': 122.0},\n",
       " 61: {'mean': 126.5, 'median': 122.0},\n",
       " 62: {'mean': 120.5, 'median': 122.0},\n",
       " 63: {'mean': 123.5, 'median': 122.0},\n",
       " 64: {'mean': 114.5, 'median': 122.0}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_frame_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4442d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not Run\n",
    "\n",
    "with open('./lsa64-data-info/nframes.json', 'w') as f:\n",
    "    json_data = json.dumps(class_frame_info)\n",
    "    f.write(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1a759e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./lsa64-data-info/nframes.json', 'r') as read_content:\n",
    "    class_frame_info = json.load(read_content)\n",
    "    class_frame_info = {int(k):v for k, v in class_frame_info.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e66075f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medians = []\n",
    "\n",
    "for class_ in classes[16:48]:\n",
    "    medians.append(class_frame_info[int(class_)]['median'])\n",
    "\n",
    "np.median(medians)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cb12e75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(88.0, 3), (118.0, 4), (122.0, 13), (137.0, 3), (152.0, 7), (182.0, 2)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = np.unique(medians, return_counts=True)\n",
    "list(zip(*m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3cb40b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_f = 0\n",
    "\n",
    "for class_ in classes[16:48]:\n",
    "    result = []\n",
    "    for file in files_for_class[class_]:\n",
    "        cap = cv2.VideoCapture(f'dataset/lsa64-data/all/{file}')\n",
    "        result.append(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        cap.release()\n",
    "    max_f = max(max_f, max(result))\n",
    "    result = np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f665b2d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "242.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3246357",
   "metadata": {},
   "source": [
    "Frames = 122, Max n_frames = 242"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e633d553",
   "metadata": {},
   "source": [
    "### Previous Model + Keras Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67201421",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fractions import Fraction\n",
    "\n",
    "def save_holistic(path, holistic, image):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    results = holistic.process(image)\n",
    "    image.flags.writeable = True\n",
    "\n",
    "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
    "    face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "\n",
    "    landmarks = np.concatenate([pose, face, lh, rh])\n",
    "    np.save(path, landmarks)\n",
    "    \n",
    "def sequential_frames(v_id, src, holistic, n_frames):\n",
    "    for f in range(n_frames):\n",
    "        ret, frame = src.read()\n",
    "        if ret:\n",
    "            save_holistic(f'./lsa64-data-info/landmarks/{v_id}/{f}.npy', holistic, frame)\n",
    "        else:\n",
    "            np.save(f'./lsa64-data-info/landmarks/{v_id}/{f}.npy', np.zeros((1662, )))\n",
    "\n",
    "def frames_from_video(v_id, n_frames):\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    mp_drawing_styles = mp.solutions.drawing_styles\n",
    "    mp_holistic = mp.solutions.holistic\n",
    "    v_id = v_id.split('.')[0]\n",
    "    \n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        src = cv2.VideoCapture(f'./dataset/lsa64-data/videos/{v_id}.mp4')\n",
    "        video_length = src.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "        os.makedirs(f'./lsa64-data-info/landmarks/{v_id}', mode=777)\n",
    "        \n",
    "        if video_length <= n_frames:\n",
    "            frame_step = 0\n",
    "            sequential_frames(v_id, src, holistic, n_frames)\n",
    "        else:\n",
    "            f = 0\n",
    "            ratio = round(video_length/n_frames, 1)\n",
    "            frac = Fraction(ratio).limit_denominator(10)\n",
    "            \n",
    "            if ratio == 1.7 or ratio == 1.9:\n",
    "                frac = Fraction(ratio).limit_denominator(2)\n",
    "            \n",
    "            num, den = frac.numerator, frac.denominator\n",
    "            while f < n_frames:\n",
    "                for _ in range(min(den, n_frames-f)):\n",
    "                    ret, frame = src.read()\n",
    "                    if ret:\n",
    "                        save_holistic(f'./lsa64-data-info/landmarks/{v_id}/{f}.npy', holistic, frame)\n",
    "                    else:\n",
    "                        np.save(f'./lsa64-data-info/landmarks/{v_id}/{f}.npy', np.zeros((1662, )))\n",
    "                    f += 1\n",
    "                for _ in range(num-den):\n",
    "                    ret, frame = src.read()\n",
    "\n",
    "        src.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a84993d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_ in classes[16:48]:\n",
    "    for v_id in files_for_class[class_]:\n",
    "        frames_from_video(v_id, 122)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b5cee6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89ed7671",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "y = [i for i in range(32)]\n",
    "y = to_categorical(y).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11069c50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{17: array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 18: array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 19: array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 20: array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 21: array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 22: array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 23: array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 24: array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 25: array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 26: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 27: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 28: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 29: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 30: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 31: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 32: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 33: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 34: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 35: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 36: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 37: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 38: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 39: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 40: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 41: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 42: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 0, 0, 0]),\n",
       " 43: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " 44: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0]),\n",
       " 45: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " 46: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 0, 0]),\n",
       " 47: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " 48: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map = {label:y[num] for num, label in enumerate(classes[16:48])}\n",
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3a67081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c87bd2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_val_test_data(classes, label_map, files_for_class, split_ratio=[0.8, 0.9]):\n",
    "    \n",
    "    result_train_v_ids = []\n",
    "    result_val_v_ids = []\n",
    "    result_test_v_ids = []\n",
    "    result_train_labels = []\n",
    "    result_val_labels = []\n",
    "    result_test_labels = []\n",
    "    \n",
    "    for class_ in classes:\n",
    "        v_ids = files_for_class[class_]\n",
    "        np.random.shuffle(v_ids)\n",
    "        split_1 = int(len(v_ids) * (split_ratio[0]))\n",
    "        split_2 = int(len(v_ids) * (split_ratio[1]))\n",
    "        result_train_v_ids.extend(v_ids[:split_1])\n",
    "        result_val_v_ids.extend(v_ids[split_1:split_2])\n",
    "        result_test_v_ids.extend(v_ids[split_2:])\n",
    "        result_train_labels.extend([label_map[class_]]*split_1)\n",
    "        result_val_labels.extend([label_map[class_]]*(split_2-split_1))\n",
    "        result_test_labels.extend([label_map[class_]]*(len(v_ids) - split_2))\n",
    "        \n",
    "    return np.array(result_train_v_ids), np.array(result_train_labels), np.array(result_val_v_ids), np.array(result_val_labels), np.array(result_test_v_ids), np.array(result_test_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "222b79d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c, d, e, f = get_train_val_test_data(classes[16:48], label_map, files_for_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10500cf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((512,), (512, 32), (64,), (64, 32), (64,), (64, 32))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape, b.shape, c.shape, d.shape, e.shape, f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d6c1bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, v_ids, labels, n_frames, batch_size = 4, training = False):\n",
    "        self.v_ids = v_ids\n",
    "        self.labels = labels\n",
    "        self.n_frames = n_frames\n",
    "        self.training = training\n",
    "        self.batch_size = batch_size\n",
    "        self.indexes = np.arange(len(self.v_ids))\n",
    "        if self.training:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def get_video_frames(self, v_ids, classes):\n",
    "        result_X = []\n",
    "        result_y = []\n",
    "        for index, v_id in enumerate(v_ids):\n",
    "            window = []\n",
    "            for f in range(self.n_frames):\n",
    "                window.append(np.load(f'./lsa64-data-info/landmarks/{v_id.split(\".\")[0]}/{f}.npy'))\n",
    "            result_X.append(np.stack(window, axis=0))\n",
    "            result_y.append(classes[index])\n",
    "        \n",
    "        return np.array(result_X), np.array(result_y)\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        return self.get_video_frames(self.v_ids[indexes], self.labels[indexes])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return math.floor(len(self.v_ids) / self.batch_size)\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.training:\n",
    "            np.random.shuffle(self.indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f029d8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = DataGenerator(a, b, 122, training=True)\n",
    "val_gen = DataGenerator(c, d, 122)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2605f11f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 122, 1662), (4, 32))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gen[0][0].shape, train_gen[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed743471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gen[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e373e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = len(train_gen)\n",
    "validation_steps = len(val_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e20f7148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, GRU\n",
    "\n",
    "model = Sequential()\n",
    "model.add(GRU(256, return_sequences=True, activation='relu', input_shape=(122, 1662)))\n",
    "model.add(GRU(128, return_sequences=True, activation='relu'))\n",
    "model.add(GRU(64, return_sequences=False, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec0cd5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_3 (GRU)                 (None, 122, 256)          1474560   \n",
      "                                                                 \n",
      " gru_4 (GRU)                 (None, 122, 128)          148224    \n",
      "                                                                 \n",
      " gru_5 (GRU)                 (None, 64)                37248     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,678,688\n",
      "Trainable params: 1,678,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ba163166",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "25acaa99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 23/128 [====>.........................] - ETA: 11:12 - loss: 3.4660 - accuracy: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mS:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mS:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mS:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mS:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mS:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mS:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mS:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mS:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mS:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(train_gen, epochs=1, steps_per_epoch=steps_per_epoch, validation_data=val_gen, validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13aa8fb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f207070",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15fb916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac2f8cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d304bce7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9ccab9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a8560b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fractions import Fraction\n",
    "\n",
    "def save_holistic(path, holistic, image):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    results = holistic.process(image)\n",
    "    image.flags.writeable = True\n",
    "\n",
    "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "\n",
    "    landmarks = np.concatenate([pose, lh, rh])\n",
    "    np.save(path, landmarks)\n",
    "    \n",
    "def sequential_frames(v_id, src, holistic, n_frames):\n",
    "    for f in range(n_frames):\n",
    "        ret, frame = src.read()\n",
    "        if ret:\n",
    "            save_holistic(f'./lsa64-data-info/landmarks-16-30-3/{v_id}/{f}.npy', holistic, frame)\n",
    "        else:\n",
    "            np.save(f'./lsa64-data-info/landmarks-16-30-3/{v_id}/{f}.npy', np.zeros((258, )))\n",
    "\n",
    "def frames_from_video(v_id, n_frames):\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    mp_drawing_styles = mp.solutions.drawing_styles\n",
    "    mp_holistic = mp.solutions.holistic\n",
    "    v_id = v_id.split('.')[0]\n",
    "    \n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        src = cv2.VideoCapture(f'./dataset/lsa64-data/videos/{v_id}.mp4')\n",
    "        video_length = src.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "        os.makedirs(f'./lsa64-data-info/landmarks-16-30-3/{v_id}', mode=777)\n",
    "        \n",
    "        if video_length <= n_frames:\n",
    "            frame_step = 0\n",
    "            sequential_frames(v_id, src, holistic, n_frames)\n",
    "        else:\n",
    "            f = 0\n",
    "            ratio = round(video_length/n_frames, 1)\n",
    "            frac = Fraction(ratio).limit_denominator(10)\n",
    "            \n",
    "            if ratio == 1.7 or ratio == 1.9:\n",
    "                frac = Fraction(ratio).limit_denominator(2)\n",
    "            \n",
    "            num, den = frac.numerator, frac.denominator\n",
    "            while f < n_frames:\n",
    "                for _ in range(min(den, n_frames-f)):\n",
    "                    ret, frame = src.read()\n",
    "                    if ret:\n",
    "                        save_holistic(f'./lsa64-data-info/landmarks-16-30-3/{v_id}/{f}.npy', holistic, frame)\n",
    "                    else:\n",
    "                        np.save(f'./lsa64-data-info/landmarks-16-30-3/{v_id}/{f}.npy', np.zeros((258, )))\n",
    "                    f += 1\n",
    "                for _ in range(num-den):\n",
    "                    ret, frame = src.read()\n",
    "\n",
    "        src.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ade08fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_ in classes[16:32]:\n",
    "    for v_id in files_for_class[class_]:\n",
    "        frames_from_video(v_id, 122)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "de76a6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "y = [i for i in range(16)]\n",
    "y = to_categorical(y).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c9297f51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{17: array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 18: array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 19: array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 20: array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 21: array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 22: array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 23: array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 24: array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 25: array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 26: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]),\n",
       " 27: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " 28: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]),\n",
       " 29: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " 30: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]),\n",
       " 31: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " 32: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map = {label:y[num] for num, label in enumerate(classes[16:32])}\n",
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "64ebdb4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(classes[16:32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "defaedb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c, d, e, f = get_train_val_test_data(classes[16:32], label_map, files_for_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6e8ac7bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((640,), (640, 16), (80,), (80, 16), (80,), (80, 16))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape, b.shape, c.shape, d.shape, e.shape, f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a3a96cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, v_ids, labels, n_frames, batch_size = 16, training = False):\n",
    "        self.v_ids = v_ids\n",
    "        self.labels = labels\n",
    "        self.n_frames = n_frames\n",
    "        self.training = training\n",
    "        self.batch_size = batch_size\n",
    "        self.indexes = np.arange(len(self.v_ids))\n",
    "        if self.training:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def get_video_frames(self, v_ids, classes):\n",
    "        result_X = []\n",
    "        result_y = []\n",
    "        for index, v_id in enumerate(v_ids):\n",
    "            window = []\n",
    "            for f in range(self.n_frames):\n",
    "                window.append(np.load(f'./lsa64-data-info/landmarks-16-30-3/{v_id.split(\".\")[0]}/{f}.npy'))\n",
    "            result_X.append(np.stack(window, axis=0))\n",
    "            result_y.append(classes[index])\n",
    "        \n",
    "        return np.array(result_X), np.array(result_y)\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        return self.get_video_frames(self.v_ids[indexes], self.labels[indexes])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return math.floor(len(self.v_ids) / self.batch_size)\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.training:\n",
    "            np.random.shuffle(self.indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "777eaef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = DataGenerator(a, b, 122, training=True)\n",
    "val_gen = DataGenerator(c, d, 122)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0da0fd0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16, 122, 258), (16, 16))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gen[0][0].shape, train_gen[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "087ff223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 16)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gen[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9ff7bea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = len(train_gen)\n",
    "validation_steps = len(val_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "44b77528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, GRU\n",
    "\n",
    "model = Sequential()\n",
    "model.add(GRU(128, return_sequences=True, activation='relu', input_shape=(122, 258)))\n",
    "model.add(GRU(64, return_sequences=True, activation='relu'))\n",
    "model.add(GRU(32, return_sequences=True, activation='relu'))\n",
    "model.add(GRU(16, return_sequences=False, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(16, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b7df90d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_4 (GRU)                 (None, 122, 128)          148992    \n",
      "                                                                 \n",
      " gru_5 (GRU)                 (None, 122, 64)           37248     \n",
      "                                                                 \n",
      " gru_6 (GRU)                 (None, 122, 32)           9408      \n",
      "                                                                 \n",
      " gru_7 (GRU)                 (None, 16)                2400      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               2176      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 16)                1040      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 209,520\n",
      "Trainable params: 209,520\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9d4c388e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "08b2e9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = len(train_gen)\n",
    "validation_steps = len(val_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b36349b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "40/40 [==============================] - 126s 3s/step - loss: 2.7731 - accuracy: 0.0453 - val_loss: 2.7726 - val_accuracy: 0.0625\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - 112s 3s/step - loss: 2.7729 - accuracy: 0.0594 - val_loss: 2.7726 - val_accuracy: 0.0625\n",
      "Epoch 3/10\n",
      "12/40 [========>.....................] - ETA: 1:11 - loss: 2.7730 - accuracy: 0.0208"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_gen, epochs=10, steps_per_epoch=steps_per_epoch, validation_data=val_gen, validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "724e0a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences, labels = [], []\n",
    "for v_id, label in zip(a, b):\n",
    "    window = []\n",
    "    for f in range(30):\n",
    "        window.append(np.load(f'./lsa64-data-info/landmarks-16-30/{v_id.split(\".\")[0]}/{f}.npy'))\n",
    "    sequences.append(np.stack(window, axis=0))\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "573da17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(sequences)\n",
    "y = np.array(labels).astype(int)\n",
    "rand_ind = np.arange(len(X))\n",
    "np.random.shuffle(rand_ind)\n",
    "X = X[rand_ind]\n",
    "y = y[rand_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ac6d1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 9/16 [===============>..............] - ETA: 5s - loss: 2.7723 - accuracy: 0.0625"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, y, batch_size=16, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4d577e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "16/16 [==============================] - 24s 837ms/step - loss: 2.7730 - accuracy: 0.0430 - val_loss: 2.7726 - val_accuracy: 0.0625\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 10s 590ms/step - loss: 2.7728 - accuracy: 0.0508 - val_loss: 2.7726 - val_accuracy: 0.0625\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 11s 607ms/step - loss: 2.7727 - accuracy: 0.0625 - val_loss: 2.7726 - val_accuracy: 0.0625\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 10s 624ms/step - loss: 2.7729 - accuracy: 0.0547 - val_loss: 2.7726 - val_accuracy: 0.0625\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 10s 562ms/step - loss: 2.7728 - accuracy: 0.0508 - val_loss: 2.7726 - val_accuracy: 0.0625\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 11s 650ms/step - loss: 2.7727 - accuracy: 0.0508 - val_loss: 2.7726 - val_accuracy: 0.0625\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 10s 638ms/step - loss: 2.7728 - accuracy: 0.0352 - val_loss: 2.7726 - val_accuracy: 0.0625\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 11s 693ms/step - loss: 2.7728 - accuracy: 0.0430 - val_loss: 2.7726 - val_accuracy: 0.0625\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 10s 595ms/step - loss: 2.7728 - accuracy: 0.0469 - val_loss: 2.7726 - val_accuracy: 0.0625\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 11s 646ms/step - loss: 2.7728 - accuracy: 0.0625 - val_loss: 2.7726 - val_accuracy: 0.0625\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_gen, epochs=10, steps_per_epoch=steps_per_epoch, validation_data=val_gen, validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e6352b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b91d643",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
